{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "suMin = float(\"inf\")\n",
    "suMax = -float(\"inf\")\n",
    "spMin = float(\"inf\")\n",
    "spMax = -float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(uFd, pFd):\n",
    "    global suMin\n",
    "    global suMax\n",
    "    global spMin\n",
    "    global spMax\n",
    "    print(\"working on file %s %s\" % (uFd.name, pFd.name))\n",
    "    x = []\n",
    "    y = []\n",
    "    while True:\n",
    "        uL = uFd.readline()\n",
    "        pL = pFd.readline()\n",
    "        if not uL and pL: raise Exception(\"Different # lines\")\n",
    "        if uL and not pL: raise Exception(\"Different # lines\")\n",
    "        if not uL and not pL: break\n",
    "            \n",
    "        t1 = uL.split(\",\")[0]\n",
    "        su = float(uL.split(\",\")[1])\n",
    "        if su != float(\"inf\") and su != -float(\"inf\") and su < suMin: suMin = su\n",
    "        if su != float(\"inf\") and su != -float(\"inf\") and su > suMax: suMax = su\n",
    "            \n",
    "        t2 = pL.split(\",\")[0]\n",
    "        sp = float(pL.split(\",\")[1])\n",
    "        if sp != float(\"inf\") and sp != -float(\"inf\") and sp < spMin: spMin = sp\n",
    "        if sp != float(\"inf\") and sp != -float(\"inf\") and sp > spMax: spMax = su\n",
    "\n",
    "            \n",
    "        if t1 != t2: raise Exception(\"Inconsistent label, %s %s\" % (pL, uL))\n",
    "        \n",
    "        x.append([su, sp]) #UA, PATH score\n",
    "        if t1 == \"m\": y.append([1,0]) #one-hot\n",
    "        elif t1 == \"b\": y.append([0,1]) #one-hot\n",
    "        else: raise Exception(\"Invalid label, %s %s\" % (pL, uL))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.train1.txt ../hmm/PATH_DATA/path-5-fold/path10/path.train1.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.test1.txt ../hmm/PATH_DATA/path-5-fold/path10/path.test1.txt\n",
      "fold 1: \n",
      "train:  1913 1913\n",
      "test:  459 459\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.train2.txt ../hmm/PATH_DATA/path-5-fold/path10/path.train2.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.test2.txt ../hmm/PATH_DATA/path-5-fold/path10/path.test2.txt\n",
      "fold 2: \n",
      "train:  1881 1881\n",
      "test:  491 491\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.train3.txt ../hmm/PATH_DATA/path-5-fold/path10/path.train3.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.test3.txt ../hmm/PATH_DATA/path-5-fold/path10/path.test3.txt\n",
      "fold 3: \n",
      "train:  1900 1900\n",
      "test:  472 472\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.train4.txt ../hmm/PATH_DATA/path-5-fold/path10/path.train4.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.test4.txt ../hmm/PATH_DATA/path-5-fold/path10/path.test4.txt\n",
      "fold 4: \n",
      "train:  1961 1961\n",
      "test:  411 411\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.train5.txt ../hmm/PATH_DATA/path-5-fold/path10/path.train5.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua10/ua.test5.txt ../hmm/PATH_DATA/path-5-fold/path10/path.test5.txt\n",
      "fold 5: \n",
      "train:  1833 1833\n",
      "test:  539 539\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 10\n",
    "ua_data = '../hmm/UA_DATA/ua-5-fold/ua%d' % SEQ_LEN \n",
    "path_data = '../hmm/PATH_DATA/path-5-fold/path%d' % SEQ_LEN\n",
    "\n",
    "folds = []\n",
    "for f in range(1,6):\n",
    "    \n",
    "    uTrain = open(\"%s/ua.train%d.txt\" % (ua_data, f), \"r\")\n",
    "    pTrain = open(\"%s/path.train%d.txt\" % (path_data, f), \"r\")\n",
    "    uTest = open(\"%s/ua.test%d.txt\" % (ua_data, f), \"r\")\n",
    "    pTest = open(\"%s/path.test%d.txt\" % (path_data, f), \"r\")\n",
    "    \n",
    "    xTrain, yTrain = getData(uTrain, pTrain)\n",
    "    xTest, yTest = getData(uTest, pTest)\n",
    "    folds.append([xTrain, yTrain, xTest, yTest])\n",
    "\n",
    "    print(\"fold %d: \" % f)\n",
    "    print(\"train: \", len(xTrain), len(yTrain))\n",
    "    print(\"test: \", len(xTest), len(yTest))\n",
    "\n",
    "#replace INF\n",
    "suMax += 1\n",
    "suMin -= 1\n",
    "spMax += 1\n",
    "spMin -= 1\n",
    "for xTrain, yTrain, xTest, yTest in folds:\n",
    "    for i in range(len(xTrain)):\n",
    "        if xTrain[i][0] == float(\"inf\"): xTrain[i][0] = suMax\n",
    "        if xTrain[i][0] == -float(\"inf\"): xTrain[i][0] = suMin\n",
    "        if xTrain[i][1] == float(\"inf\"): xTrain[i][1] = spMax\n",
    "        if xTrain[i][1] == -float(\"inf\"): xTrain[i][1] = spMin \n",
    "    for i in range(len(xTest)):\n",
    "        if xTest[i][0] == float(\"inf\"): xTest[i][0] = suMax\n",
    "        if xTest[i][0] == -float(\"inf\"): xTest[i][0] = suMin\n",
    "        if xTest[i][1] == float(\"inf\"): xTest[i][1] = spMax\n",
    "        if xTest[i][1] == -float(\"inf\"): xTest[i][1] = spMin \n",
    "\n",
    "#normalized it to 0 to 1\n",
    "for xTrain, yTrain, xTest, yTest in folds:\n",
    "    for i in range(len(xTrain)):\n",
    "        xTrain[i][0] = (xTrain[i][0] - suMin) / (suMax - suMin)\n",
    "        xTrain[i][1] = (xTrain[i][1] - spMin) / (spMax - spMin)\n",
    "    for i in range(len(xTest)):\n",
    "        xTest[i][0] = (xTest[i][0] - suMin) / (suMax - suMin)\n",
    "        xTest[i][1] = (xTest[i][1] - spMin) / (spMax - spMin)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1913 samples, validate on 459 samples\n",
      "Epoch 1/20\n",
      "1913/1913 [==============================] - 1s 481us/step - loss: 0.5384 - acc: 0.7841 - val_loss: 0.4820 - val_acc: 0.8170\n",
      "Epoch 2/20\n",
      "1913/1913 [==============================] - 0s 74us/step - loss: 0.5247 - acc: 0.7841 - val_loss: 0.4785 - val_acc: 0.8170\n",
      "Epoch 3/20\n",
      "1913/1913 [==============================] - 0s 75us/step - loss: 0.5234 - acc: 0.7841 - val_loss: 0.4765 - val_acc: 0.8170\n",
      "Epoch 4/20\n",
      "1913/1913 [==============================] - 0s 71us/step - loss: 0.5202 - acc: 0.7841 - val_loss: 0.4784 - val_acc: 0.8170\n",
      "Epoch 5/20\n",
      "1913/1913 [==============================] - 0s 71us/step - loss: 0.5168 - acc: 0.7841 - val_loss: 0.4715 - val_acc: 0.8170\n",
      "Epoch 6/20\n",
      "1913/1913 [==============================] - 0s 71us/step - loss: 0.5209 - acc: 0.7841 - val_loss: 0.4718 - val_acc: 0.8170\n",
      "Epoch 7/20\n",
      "1913/1913 [==============================] - 0s 72us/step - loss: 0.5092 - acc: 0.7841 - val_loss: 0.4748 - val_acc: 0.8170\n",
      "Epoch 8/20\n",
      "1913/1913 [==============================] - 0s 77us/step - loss: 0.4985 - acc: 0.7841 - val_loss: 0.4591 - val_acc: 0.8170\n",
      "Epoch 9/20\n",
      "1913/1913 [==============================] - 0s 77us/step - loss: 0.4906 - acc: 0.7841 - val_loss: 0.4651 - val_acc: 0.8170\n",
      "Epoch 10/20\n",
      "1913/1913 [==============================] - 0s 75us/step - loss: 0.4808 - acc: 0.7841 - val_loss: 0.4704 - val_acc: 0.8170\n",
      "Epoch 11/20\n",
      "1913/1913 [==============================] - 0s 76us/step - loss: 0.4639 - acc: 0.7841 - val_loss: 0.4730 - val_acc: 0.8170\n",
      "Epoch 12/20\n",
      "1913/1913 [==============================] - 0s 74us/step - loss: 0.4664 - acc: 0.7841 - val_loss: 0.4363 - val_acc: 0.8170\n",
      "Epoch 13/20\n",
      "1913/1913 [==============================] - 0s 76us/step - loss: 0.4555 - acc: 0.7841 - val_loss: 0.4442 - val_acc: 0.8170\n",
      "Epoch 14/20\n",
      "1913/1913 [==============================] - 0s 78us/step - loss: 0.4531 - acc: 0.7841 - val_loss: 0.4304 - val_acc: 0.8170\n",
      "Epoch 15/20\n",
      "1913/1913 [==============================] - 0s 75us/step - loss: 0.4661 - acc: 0.7841 - val_loss: 0.4583 - val_acc: 0.8170\n",
      "Epoch 16/20\n",
      "1913/1913 [==============================] - 0s 75us/step - loss: 0.4582 - acc: 0.7841 - val_loss: 0.4319 - val_acc: 0.8170\n",
      "Epoch 17/20\n",
      "1913/1913 [==============================] - 0s 84us/step - loss: 0.4545 - acc: 0.7841 - val_loss: 0.4295 - val_acc: 0.8170\n",
      "Epoch 18/20\n",
      "1913/1913 [==============================] - 0s 77us/step - loss: 0.4496 - acc: 0.7841 - val_loss: 0.4322 - val_acc: 0.8170\n",
      "Epoch 19/20\n",
      "1913/1913 [==============================] - 0s 75us/step - loss: 0.4451 - acc: 0.7841 - val_loss: 0.4428 - val_acc: 0.8170\n",
      "Epoch 20/20\n",
      "1913/1913 [==============================] - 0s 76us/step - loss: 0.4488 - acc: 0.7841 - val_loss: 0.4582 - val_acc: 0.8170\n",
      "459/459 [==============================] - 0s 32us/step\n",
      "Train on 1881 samples, validate on 491 samples\n",
      "Epoch 1/20\n",
      "1881/1881 [==============================] - 1s 507us/step - loss: 0.5119 - acc: 0.7974 - val_loss: 0.5308 - val_acc: 0.7637\n",
      "Epoch 2/20\n",
      "1881/1881 [==============================] - 0s 106us/step - loss: 0.4928 - acc: 0.7974 - val_loss: 0.5264 - val_acc: 0.7637\n",
      "Epoch 3/20\n",
      "1881/1881 [==============================] - 0s 101us/step - loss: 0.4909 - acc: 0.7974 - val_loss: 0.5249 - val_acc: 0.7637\n",
      "Epoch 4/20\n",
      "1881/1881 [==============================] - 0s 90us/step - loss: 0.4924 - acc: 0.7974 - val_loss: 0.5229 - val_acc: 0.7637\n",
      "Epoch 5/20\n",
      "1881/1881 [==============================] - 0s 99us/step - loss: 0.4907 - acc: 0.7974 - val_loss: 0.5243 - val_acc: 0.7637\n",
      "Epoch 6/20\n",
      "1881/1881 [==============================] - 0s 93us/step - loss: 0.4911 - acc: 0.7974 - val_loss: 0.5266 - val_acc: 0.7637\n",
      "Epoch 7/20\n",
      "1881/1881 [==============================] - 0s 90us/step - loss: 0.4924 - acc: 0.7974 - val_loss: 0.5225 - val_acc: 0.7637\n",
      "Epoch 8/20\n",
      "1881/1881 [==============================] - 0s 99us/step - loss: 0.4911 - acc: 0.7974 - val_loss: 0.5335 - val_acc: 0.7637\n",
      "Epoch 9/20\n",
      "1881/1881 [==============================] - 0s 86us/step - loss: 0.4909 - acc: 0.7974 - val_loss: 0.5226 - val_acc: 0.7637\n",
      "Epoch 10/20\n",
      "1881/1881 [==============================] - 0s 76us/step - loss: 0.4913 - acc: 0.7974 - val_loss: 0.5279 - val_acc: 0.7637\n",
      "Epoch 11/20\n",
      "1881/1881 [==============================] - 0s 80us/step - loss: 0.4894 - acc: 0.7974 - val_loss: 0.5217 - val_acc: 0.7637\n",
      "Epoch 12/20\n",
      "1881/1881 [==============================] - 0s 92us/step - loss: 0.4891 - acc: 0.7974 - val_loss: 0.5302 - val_acc: 0.7637\n",
      "Epoch 13/20\n",
      "1881/1881 [==============================] - 0s 93us/step - loss: 0.4872 - acc: 0.7974 - val_loss: 0.5219 - val_acc: 0.7637\n",
      "Epoch 14/20\n",
      "1881/1881 [==============================] - 0s 90us/step - loss: 0.4921 - acc: 0.7974 - val_loss: 0.5214 - val_acc: 0.7637\n",
      "Epoch 15/20\n",
      "1881/1881 [==============================] - 0s 90us/step - loss: 0.4890 - acc: 0.7974 - val_loss: 0.5218 - val_acc: 0.7637\n",
      "Epoch 16/20\n",
      "1881/1881 [==============================] - 0s 93us/step - loss: 0.4876 - acc: 0.7974 - val_loss: 0.5212 - val_acc: 0.7637\n",
      "Epoch 17/20\n",
      "1881/1881 [==============================] - 0s 88us/step - loss: 0.4875 - acc: 0.7974 - val_loss: 0.5237 - val_acc: 0.7637\n",
      "Epoch 18/20\n",
      "1881/1881 [==============================] - 0s 92us/step - loss: 0.4878 - acc: 0.7974 - val_loss: 0.5357 - val_acc: 0.7637\n",
      "Epoch 19/20\n",
      "1881/1881 [==============================] - 0s 79us/step - loss: 0.4907 - acc: 0.7974 - val_loss: 0.5318 - val_acc: 0.7637\n",
      "Epoch 20/20\n",
      "1881/1881 [==============================] - 0s 74us/step - loss: 0.4865 - acc: 0.7974 - val_loss: 0.5329 - val_acc: 0.7637\n",
      "491/491 [==============================] - 0s 33us/step\n",
      "Train on 1900 samples, validate on 472 samples\n",
      "Epoch 1/20\n",
      "1900/1900 [==============================] - 1s 528us/step - loss: 0.5418 - acc: 0.7811 - val_loss: 0.5066 - val_acc: 0.7945\n",
      "Epoch 2/20\n",
      "1900/1900 [==============================] - 0s 77us/step - loss: 0.5191 - acc: 0.7895 - val_loss: 0.5067 - val_acc: 0.7945\n",
      "Epoch 3/20\n",
      "1900/1900 [==============================] - 0s 75us/step - loss: 0.5164 - acc: 0.7895 - val_loss: 0.5092 - val_acc: 0.7945\n",
      "Epoch 4/20\n",
      "1900/1900 [==============================] - 0s 74us/step - loss: 0.5166 - acc: 0.7895 - val_loss: 0.5102 - val_acc: 0.7945\n",
      "Epoch 5/20\n",
      "1900/1900 [==============================] - 0s 86us/step - loss: 0.5169 - acc: 0.7895 - val_loss: 0.5086 - val_acc: 0.7945\n",
      "Epoch 6/20\n",
      "1900/1900 [==============================] - 0s 81us/step - loss: 0.5171 - acc: 0.7895 - val_loss: 0.5175 - val_acc: 0.7945\n",
      "Epoch 7/20\n",
      "1900/1900 [==============================] - 0s 82us/step - loss: 0.5150 - acc: 0.7895 - val_loss: 0.5090 - val_acc: 0.7945\n",
      "Epoch 8/20\n",
      "1900/1900 [==============================] - 0s 85us/step - loss: 0.5167 - acc: 0.7895 - val_loss: 0.5272 - val_acc: 0.7945\n",
      "Epoch 9/20\n",
      "1900/1900 [==============================] - 0s 78us/step - loss: 0.5153 - acc: 0.7895 - val_loss: 0.5117 - val_acc: 0.7945\n",
      "Epoch 10/20\n",
      "1900/1900 [==============================] - 0s 87us/step - loss: 0.5124 - acc: 0.7895 - val_loss: 0.5075 - val_acc: 0.7945\n",
      "Epoch 11/20\n",
      "1900/1900 [==============================] - 0s 82us/step - loss: 0.5099 - acc: 0.7895 - val_loss: 0.5097 - val_acc: 0.7945\n",
      "Epoch 12/20\n",
      "1900/1900 [==============================] - 0s 81us/step - loss: 0.5080 - acc: 0.7895 - val_loss: 0.5083 - val_acc: 0.7945\n",
      "Epoch 13/20\n",
      "1900/1900 [==============================] - 0s 78us/step - loss: 0.5083 - acc: 0.7895 - val_loss: 0.5097 - val_acc: 0.7945\n",
      "Epoch 14/20\n",
      "1900/1900 [==============================] - 0s 86us/step - loss: 0.5085 - acc: 0.7895 - val_loss: 0.5098 - val_acc: 0.7945\n",
      "Epoch 15/20\n",
      "1900/1900 [==============================] - 0s 85us/step - loss: 0.5051 - acc: 0.7895 - val_loss: 0.5072 - val_acc: 0.7945\n",
      "Epoch 16/20\n",
      "1900/1900 [==============================] - 0s 83us/step - loss: 0.5042 - acc: 0.7895 - val_loss: 0.5055 - val_acc: 0.7945\n",
      "Epoch 17/20\n",
      "1900/1900 [==============================] - 0s 83us/step - loss: 0.4987 - acc: 0.7895 - val_loss: 0.5040 - val_acc: 0.7945\n",
      "Epoch 18/20\n",
      "1900/1900 [==============================] - 0s 83us/step - loss: 0.5018 - acc: 0.7895 - val_loss: 0.5092 - val_acc: 0.7945\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900/1900 [==============================] - 0s 86us/step - loss: 0.5012 - acc: 0.7895 - val_loss: 0.5038 - val_acc: 0.7945\n",
      "Epoch 20/20\n",
      "1900/1900 [==============================] - 0s 77us/step - loss: 0.4972 - acc: 0.7895 - val_loss: 0.5058 - val_acc: 0.7945\n",
      "472/472 [==============================] - 0s 34us/step\n",
      "Train on 1961 samples, validate on 411 samples\n",
      "Epoch 1/20\n",
      "1961/1961 [==============================] - 1s 574us/step - loss: 0.5657 - acc: 0.7568 - val_loss: 0.3750 - val_acc: 0.9124\n",
      "Epoch 2/20\n",
      "1961/1961 [==============================] - 0s 84us/step - loss: 0.5265 - acc: 0.7649 - val_loss: 0.3599 - val_acc: 0.9124\n",
      "Epoch 3/20\n",
      "1961/1961 [==============================] - 0s 70us/step - loss: 0.5054 - acc: 0.7649 - val_loss: 0.3706 - val_acc: 0.9124\n",
      "Epoch 4/20\n",
      "1961/1961 [==============================] - 0s 71us/step - loss: 0.5006 - acc: 0.7649 - val_loss: 0.3634 - val_acc: 0.9124\n",
      "Epoch 5/20\n",
      "1961/1961 [==============================] - 0s 73us/step - loss: 0.5000 - acc: 0.7649 - val_loss: 0.3689 - val_acc: 0.9124\n",
      "Epoch 6/20\n",
      "1961/1961 [==============================] - 0s 71us/step - loss: 0.5013 - acc: 0.7649 - val_loss: 0.3201 - val_acc: 0.9124\n",
      "Epoch 7/20\n",
      "1961/1961 [==============================] - 0s 72us/step - loss: 0.5007 - acc: 0.7649 - val_loss: 0.3523 - val_acc: 0.9124\n",
      "Epoch 8/20\n",
      "1961/1961 [==============================] - 0s 71us/step - loss: 0.4988 - acc: 0.7649 - val_loss: 0.3286 - val_acc: 0.9124\n",
      "Epoch 9/20\n",
      "1961/1961 [==============================] - 0s 70us/step - loss: 0.4996 - acc: 0.7649 - val_loss: 0.3268 - val_acc: 0.9124\n",
      "Epoch 10/20\n",
      "1961/1961 [==============================] - 0s 65us/step - loss: 0.4993 - acc: 0.7649 - val_loss: 0.3512 - val_acc: 0.9124\n",
      "Epoch 11/20\n",
      "1961/1961 [==============================] - 0s 67us/step - loss: 0.4998 - acc: 0.7649 - val_loss: 0.3517 - val_acc: 0.9124\n",
      "Epoch 12/20\n",
      "1961/1961 [==============================] - 0s 70us/step - loss: 0.4995 - acc: 0.7649 - val_loss: 0.3524 - val_acc: 0.9124\n",
      "Epoch 13/20\n",
      "1961/1961 [==============================] - 0s 67us/step - loss: 0.4979 - acc: 0.7649 - val_loss: 0.3737 - val_acc: 0.9124\n",
      "Epoch 14/20\n",
      "1961/1961 [==============================] - 0s 73us/step - loss: 0.4992 - acc: 0.7649 - val_loss: 0.3391 - val_acc: 0.9124\n",
      "Epoch 15/20\n",
      "1961/1961 [==============================] - 0s 69us/step - loss: 0.4986 - acc: 0.7649 - val_loss: 0.3477 - val_acc: 0.9124\n",
      "Epoch 16/20\n",
      "1961/1961 [==============================] - 0s 66us/step - loss: 0.4998 - acc: 0.7649 - val_loss: 0.3738 - val_acc: 0.9124\n",
      "Epoch 17/20\n",
      "1961/1961 [==============================] - 0s 71us/step - loss: 0.5012 - acc: 0.7649 - val_loss: 0.3261 - val_acc: 0.9124\n",
      "Epoch 18/20\n",
      "1961/1961 [==============================] - 0s 101us/step - loss: 0.4996 - acc: 0.7649 - val_loss: 0.3502 - val_acc: 0.9124\n",
      "Epoch 19/20\n",
      "1961/1961 [==============================] - 0s 84us/step - loss: 0.4999 - acc: 0.7649 - val_loss: 0.3460 - val_acc: 0.9124\n",
      "Epoch 20/20\n",
      "1961/1961 [==============================] - 0s 73us/step - loss: 0.4997 - acc: 0.7649 - val_loss: 0.3470 - val_acc: 0.9124\n",
      "411/411 [==============================] - 0s 34us/step\n",
      "Train on 1833 samples, validate on 539 samples\n",
      "Epoch 1/20\n",
      "1833/1833 [==============================] - 1s 605us/step - loss: 0.4948 - acc: 0.8091 - val_loss: 0.6749 - val_acc: 0.6957\n",
      "Epoch 2/20\n",
      "1833/1833 [==============================] - 0s 80us/step - loss: 0.4571 - acc: 0.8183 - val_loss: 0.7451 - val_acc: 0.6957\n",
      "Epoch 3/20\n",
      "1833/1833 [==============================] - 0s 91us/step - loss: 0.4490 - acc: 0.8183 - val_loss: 0.8710 - val_acc: 0.6957\n",
      "Epoch 4/20\n",
      "1833/1833 [==============================] - 0s 88us/step - loss: 0.4373 - acc: 0.8183 - val_loss: 0.9302 - val_acc: 0.6957\n",
      "Epoch 5/20\n",
      "1833/1833 [==============================] - 0s 90us/step - loss: 0.4324 - acc: 0.8183 - val_loss: 1.0759 - val_acc: 0.6957\n",
      "Epoch 6/20\n",
      "1833/1833 [==============================] - 0s 82us/step - loss: 0.4305 - acc: 0.8183 - val_loss: 1.2470 - val_acc: 0.6957\n",
      "Epoch 7/20\n",
      "1833/1833 [==============================] - 0s 90us/step - loss: 0.4332 - acc: 0.8183 - val_loss: 1.2904 - val_acc: 0.6957\n",
      "Epoch 8/20\n",
      "1833/1833 [==============================] - 0s 89us/step - loss: 0.4311 - acc: 0.8183 - val_loss: 1.3397 - val_acc: 0.6957\n",
      "Epoch 9/20\n",
      "1833/1833 [==============================] - 0s 79us/step - loss: 0.4314 - acc: 0.8183 - val_loss: 1.4535 - val_acc: 0.6957\n",
      "Epoch 10/20\n",
      "1833/1833 [==============================] - 0s 81us/step - loss: 0.4286 - acc: 0.8183 - val_loss: 1.4896 - val_acc: 0.6957\n",
      "Epoch 11/20\n",
      "1833/1833 [==============================] - 0s 94us/step - loss: 0.4281 - acc: 0.8183 - val_loss: 1.5988 - val_acc: 0.6957\n",
      "Epoch 12/20\n",
      "1833/1833 [==============================] - 0s 85us/step - loss: 0.4298 - acc: 0.8183 - val_loss: 1.6739 - val_acc: 0.6957\n",
      "Epoch 13/20\n",
      "1833/1833 [==============================] - 0s 83us/step - loss: 0.4287 - acc: 0.8183 - val_loss: 1.7130 - val_acc: 0.6957\n",
      "Epoch 14/20\n",
      "1833/1833 [==============================] - 0s 93us/step - loss: 0.4282 - acc: 0.8183 - val_loss: 1.7300 - val_acc: 0.6957\n",
      "Epoch 15/20\n",
      "1833/1833 [==============================] - 0s 91us/step - loss: 0.4280 - acc: 0.8183 - val_loss: 1.7635 - val_acc: 0.6957\n",
      "Epoch 16/20\n",
      "1833/1833 [==============================] - 0s 85us/step - loss: 0.4287 - acc: 0.8183 - val_loss: 1.6450 - val_acc: 0.6957\n",
      "Epoch 17/20\n",
      "1833/1833 [==============================] - 0s 82us/step - loss: 0.4284 - acc: 0.8183 - val_loss: 1.7164 - val_acc: 0.6957\n",
      "Epoch 18/20\n",
      "1833/1833 [==============================] - 0s 88us/step - loss: 0.4282 - acc: 0.8183 - val_loss: 1.7325 - val_acc: 0.6957\n",
      "Epoch 19/20\n",
      "1833/1833 [==============================] - 0s 89us/step - loss: 0.4284 - acc: 0.8183 - val_loss: 1.7139 - val_acc: 0.6957\n",
      "Epoch 20/20\n",
      "1833/1833 [==============================] - 0s 90us/step - loss: 0.4285 - acc: 0.8183 - val_loss: 1.7117 - val_acc: 0.6957\n",
      "539/539 [==============================] - 0s 36us/step\n",
      "fold 1 has accuracy: 0.816993464052\n",
      "fold 2 has accuracy: 0.763747454175\n",
      "fold 3 has accuracy: 0.794491525424\n",
      "fold 4 has accuracy: 0.912408759124\n",
      "fold 5 has accuracy: 0.69573283859\n",
      "5 fold min 0.69573283859, max 0.912408759124, avg 0.796674808273\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "def getModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "fold_acc = []\n",
    "for fold_num in range(5):\n",
    "    xTrain, yTrain, xTest, yTest = folds[fold_num]\n",
    "    xTrain = np.array(xTrain)\n",
    "    yTrain = np.array(yTrain)\n",
    "    xTest = np.array(xTest)\n",
    "    yTest = np.array(yTest)\n",
    "    model = getModel()\n",
    "    model.fit(xTrain, yTrain, epochs=20, batch_size=32, validation_data=(xTest, yTest))\n",
    "    fold_acc.append(model.evaluate(xTest, yTest)[1])\n",
    "    \n",
    "for fold_num in range(5):\n",
    "    print(\"fold %s has accuracy: %s\" % (fold_num+1, fold_acc[fold_num]))\n",
    "print(\"5 fold min %s, max %s, avg %s\" % (min(fold_acc), max(fold_acc), sum(fold_acc)/5,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-tf",
   "language": "python",
   "name": "keras-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
