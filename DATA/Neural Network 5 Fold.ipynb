{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "suMin = float(\"inf\")\n",
    "suMax = -float(\"inf\")\n",
    "spMin = float(\"inf\")\n",
    "spMax = -float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(uFd, pFd):\n",
    "    global suMin\n",
    "    global suMax\n",
    "    global spMin\n",
    "    global spMax\n",
    "    print(\"working on file %s %s\" % (uFd.name, pFd.name))\n",
    "    x = []\n",
    "    y = []\n",
    "    while True:\n",
    "        uL = uFd.readline()\n",
    "        pL = pFd.readline()\n",
    "        if not uL and pL: raise Exception(\"Different # lines\")\n",
    "        if uL and not pL: raise Exception(\"Different # lines\")\n",
    "        if not uL and not pL: break\n",
    "            \n",
    "        t1 = uL.split(\",\")[0]\n",
    "        su = float(uL.split(\",\")[1])\n",
    "        if su != float(\"inf\") and su != -float(\"inf\") and su < suMin: suMin = su\n",
    "        if su != float(\"inf\") and su != -float(\"inf\") and su > suMax: suMax = su\n",
    "            \n",
    "        t2 = pL.split(\",\")[0]\n",
    "        sp = float(pL.split(\",\")[1])\n",
    "        if sp != float(\"inf\") and sp != -float(\"inf\") and sp < spMin: spMin = sp\n",
    "        if sp != float(\"inf\") and sp != -float(\"inf\") and sp > spMax: spMax = su\n",
    "\n",
    "            \n",
    "        if t1 != t2: raise Exception(\"Inconsistent label, %s %s\" % (pL, uL))\n",
    "        \n",
    "        x.append([su, sp]) #UA, PATH score\n",
    "        if t1 == \"m\": y.append([1,0]) #one-hot\n",
    "        elif t1 == \"b\": y.append([0,1]) #one-hot\n",
    "        else: raise Exception(\"Invalid label, %s %s\" % (pL, uL))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.train1.txt ../hmm/PATH_DATA/path-5-fold/path40/path.train1.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.test1.txt ../hmm/PATH_DATA/path-5-fold/path40/path.test1.txt\n",
      "fold 1: \n",
      "train:  1673 1673\n",
      "test:  399 399\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.train2.txt ../hmm/PATH_DATA/path-5-fold/path40/path.train2.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.test2.txt ../hmm/PATH_DATA/path-5-fold/path40/path.test2.txt\n",
      "fold 2: \n",
      "train:  1641 1641\n",
      "test:  431 431\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.train3.txt ../hmm/PATH_DATA/path-5-fold/path40/path.train3.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.test3.txt ../hmm/PATH_DATA/path-5-fold/path40/path.test3.txt\n",
      "fold 3: \n",
      "train:  1660 1660\n",
      "test:  412 412\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.train4.txt ../hmm/PATH_DATA/path-5-fold/path40/path.train4.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.test4.txt ../hmm/PATH_DATA/path-5-fold/path40/path.test4.txt\n",
      "fold 4: \n",
      "train:  1721 1721\n",
      "test:  351 351\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.train5.txt ../hmm/PATH_DATA/path-5-fold/path40/path.train5.txt\n",
      "working on file ../hmm/UA_DATA/ua-5-fold/ua40/ua.test5.txt ../hmm/PATH_DATA/path-5-fold/path40/path.test5.txt\n",
      "fold 5: \n",
      "train:  1593 1593\n",
      "test:  479 479\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 40\n",
    "ua_data = '../hmm/UA_DATA/ua-5-fold/ua%d' % SEQ_LEN \n",
    "path_data = '../hmm/PATH_DATA/path-5-fold/path%d' % SEQ_LEN\n",
    "\n",
    "folds = []\n",
    "for f in range(1,6):\n",
    "    \n",
    "    uTrain = open(\"%s/ua.train%d.txt\" % (ua_data, f), \"r\")\n",
    "    pTrain = open(\"%s/path.train%d.txt\" % (path_data, f), \"r\")\n",
    "    uTest = open(\"%s/ua.test%d.txt\" % (ua_data, f), \"r\")\n",
    "    pTest = open(\"%s/path.test%d.txt\" % (path_data, f), \"r\")\n",
    "    \n",
    "    xTrain, yTrain = getData(uTrain, pTrain)\n",
    "    xTest, yTest = getData(uTest, pTest)\n",
    "    folds.append([xTrain, yTrain, xTest, yTest])\n",
    "\n",
    "    print(\"fold %d: \" % f)\n",
    "    print(\"train: \", len(xTrain), len(yTrain))\n",
    "    print(\"test: \", len(xTest), len(yTest))\n",
    "\n",
    "#replace INF\n",
    "suMax += 1\n",
    "suMin -= 1\n",
    "spMax += 1\n",
    "spMin -= 1\n",
    "for xTrain, yTrain, xTest, yTest in folds:\n",
    "    for i in range(len(xTrain)):\n",
    "        if xTrain[i][0] == float(\"inf\"): xTrain[i][0] = suMax\n",
    "        if xTrain[i][0] == -float(\"inf\"): xTrain[i][0] = suMin\n",
    "        if xTrain[i][1] == float(\"inf\"): xTrain[i][1] = spMax\n",
    "        if xTrain[i][1] == -float(\"inf\"): xTrain[i][1] = spMin \n",
    "    for i in range(len(xTest)):\n",
    "        if xTest[i][0] == float(\"inf\"): xTest[i][0] = suMax\n",
    "        if xTest[i][0] == -float(\"inf\"): xTest[i][0] = suMin\n",
    "        if xTest[i][1] == float(\"inf\"): xTest[i][1] = spMax\n",
    "        if xTest[i][1] == -float(\"inf\"): xTest[i][1] = spMin \n",
    "\n",
    "#normalized it to 0 to 1\n",
    "for xTrain, yTrain, xTest, yTest in folds:\n",
    "    for i in range(len(xTrain)):\n",
    "        xTrain[i][0] = (xTrain[i][0] - suMin) / (suMax - suMin)\n",
    "        xTrain[i][1] = (xTrain[i][1] - spMin) / (spMax - spMin)\n",
    "    for i in range(len(xTest)):\n",
    "        xTest[i][0] = (xTest[i][0] - suMin) / (suMax - suMin)\n",
    "        xTest[i][1] = (xTest[i][1] - spMin) / (spMax - spMin)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 : cm = \n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "fold 1 : cm = \n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "fold 2 : cm = \n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "fold 3 : cm = \n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "fold 4 : cm = \n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "fold 1 has accuracy: 0.864661654135\n",
      "fold 2 has accuracy: 0.800464037123\n",
      "fold 3 has accuracy: 0.837378640777\n",
      "fold 4 has accuracy: 0.982905982906\n",
      "fold 5 has accuracy: 0.720250521921\n",
      "5 fold min 0.720250521921, max 0.982905982906, avg 0.841132167372\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9d078d908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getCate(arr):\n",
    "    print(arr.shape)\n",
    "    l = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        if np.argmax(arr[i]) == 0: l.append(-1)\n",
    "        else: l.append(1)\n",
    "    return l\n",
    "\n",
    "def getModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "fold_acc = []\n",
    "cms = []\n",
    "for fold_num in range(5):\n",
    "    xTrain, yTrain, xTest, yTest = folds[fold_num]\n",
    "    numTests = len(yTest)\n",
    "\n",
    "    xTrain = np.array(xTrain)\n",
    "    xTest = np.array(xTest)\n",
    "\n",
    "    #Neural Network\n",
    "#     yTrain = np.array(yTrain)\n",
    "#     yTest = np.array(yTest)\n",
    "#     model = getModel()\n",
    "#     model.fit(xTrain, yTrain, epochs=20, batch_size=32, validation_data=(xTest, yTest), verbose=0)\n",
    "#     fold_acc.append(model.evaluate(xTest, yTest)[1])\n",
    "#     cm = confusion_matrix(getCate(yTest), getCate(model.predict(xTest)))\n",
    "#     cm = normalize(cm, axis=1, norm='l1')\n",
    "#     cms.append(cm)\n",
    "#     print(\"fold %d : cm = \\n%s\" % (fold_num, cm))\n",
    "    \n",
    "        \n",
    "    #SVM\n",
    "    yTrain = np.array([a.index(max(a)) for a in yTrain]) #convert back one-hot to label\n",
    "    yTest = np.array([a.index(max(a)) for a in yTest])\n",
    "    kernel =  'rbf' #‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’\n",
    "    clf = SVC(kernel=kernel)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    fold_acc.append(clf.score(xTest, yTest))\n",
    "    if kernel == 'linear': print(\"fold %d : coef = %s\" % (fold_num, clf.coef_))\n",
    "    cm = confusion_matrix(yTest, clf.predict(xTest))\n",
    "    cm = normalize(cm, axis=1, norm='l1')\n",
    "    cms.append(cm)\n",
    "    print(\"fold %d : cm = \\n%s\" % (fold_num, cm))\n",
    "\n",
    "cm = cms[0]\n",
    "for i in range(1,len(cms)): cm += cms[i]\n",
    "cm = cm / len(cms)\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in \"MB\"], columns = [i for i in \"MB\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "    \n",
    "for fold_num in range(5):\n",
    "    print(\"fold %s has accuracy: %s\" % (fold_num+1, fold_acc[fold_num]))\n",
    "print(\"5 fold min %s, max %s, avg %s\" % (min(fold_acc), max(fold_acc), sum(fold_acc)/5,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-tf",
   "language": "python",
   "name": "keras-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
